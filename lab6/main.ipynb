{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzvFXKTPuTVj"
   },
   "source": [
    "# Przetwarzanie wstępne. Filtracja kontekstowa.\n",
    "\n",
    "\n",
    "### Cel:\n",
    "- zapoznanie z pojęciem kontekstu / filtracji kontekstowej,\n",
    "- zapoznanie z pojęciem konwolucji (splotu),\n",
    "- zapoznanie z wybranymi filtrami:\n",
    "\t- filtry liniowe dolnoprzepustowe:\n",
    "\t\t- filtr uśredniający,\n",
    "\t\t- filtr Gaussa.\n",
    "\t- filtry nielinowe:\n",
    "\t\t- mediana,\n",
    "\t\t- mediana dla obrazów kolorowych.\n",
    "\t- filtry liniowe górnoprzepustowe:\n",
    "\t\t\t- laplasjan,\n",
    "\t\t\t- operator Robersta, Prewitta, Sobela.\n",
    "- zadanie domowe: adaptacyjna filtracja medianowa.\n",
    "\n",
    "### Filtry liniowe uśredniające (dolnoprzepustowe)\n",
    "\n",
    "Jest to podstawowa rodzina filtrów stosowana w cyfrowym przetwarzaniu obrazów. \n",
    "Wykorzystuje się je w celu \"rozmazania\" obrazu i tym samym redukcji szumów (zakłóceń) na obrazie.\n",
    "Filtr określony jest przez dwa parametry: rozmiar maski (ang. _kernel_) oraz wartości współczynników maski.\n",
    "\n",
    "Warto zwrócić uwagę, że omawiane w niniejszym rozdziale operacje generują nową wartość piksela na podstawie pewnego fragmentu obrazu (tj. kontekstu), a nie jak operacje punktowe tylko na podstawie jednego piksela.\n",
    "\n",
    "\n",
    "1. Wczytaj obraz _plansza.png_.\n",
    "W dalszej części ćwiczenia sprawdzenie działania filtracji dla innych obrazów sprowadzi się do wczytania innego pliku.\n",
    "\n",
    "2. Podstawowa funkcja to `cv2.filter2D`  - realizacja filtracji konwolucyjnej.\n",
    "   Proszę sprawdzić jej dokumentację i zwrócić uwagę na obsługę problemu brzegowego (na krawędziach istnieją piksele dla których nie da się wyznaczyć otoczenia).\n",
    "\n",
    "  Uwaga. Problem ten można też rozwiązać z użyciem funkcji `signal.convolve2d` z biblioteki _scipy_ (`from scipy import signal`).\n",
    "\n",
    "3. Stwórz podstawowy filtr uśredniający o rozmiarze $3 \\times 3$ -- za pomocą funkcji `np.ones`. Wykonaj konwolucję na wczytanym obrazie. Na wspólnym rysunku wyświetl obraz oryginalny, po filtracji oraz moduł z różnicy.\n",
    "\n",
    "4. Przeanalizuj otrzymane wyniki. Jakie elementy zawiera obraz \"moduł z różnicy\"? Co na tej podstawie można powiedzieć o filtracji dolnoprzepustowej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4Cq3WvAuTVm"
   },
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/vision-agh/poc_sw/master/06_Context/'\n",
    "\n",
    "fileNames = [\"jet.png\", \"kw.png\", \"moon.png\", \"lenaSzum.png\", \"lena.png\", \"plansza.png\"]\n",
    "for fileName in fileNames:\n",
    "  if not os.path.exists(fileName):\n",
    "      r = requests.get(url + fileName, allow_redirects=True)\n",
    "      open(fileName, 'wb').write(r.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plansza = cv2.imread(\"plansza.png\", cv2.IMREAD_GRAYSCALE)\n",
    "N = 3\n",
    "kernel = np.ones((N, N)) / (N ** 2)\n",
    "\n",
    "signed_plansza = np.copy(plansza).astype(np.int16)\n",
    "convolved_plansza = cv2.filter2D(src=signed_plansza, ddepth=-1, kernel=kernel).astype(np.int16)\n",
    "\n",
    "fig, (src, dest, diff) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ax in (src, dest, diff):\n",
    "    ax.axis('off')\n",
    "src.imshow(signed_plansza, cmap=\"gray\")\n",
    "dest.imshow(convolved_plansza, cmap=\"gray\")\n",
    "diff.imshow(np.abs(signed_plansza - convolved_plansza), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10zj2sOTuTVo"
   },
   "source": [
    "5. Na wspólnym rysunku wyświetl wyniki filtracji uśredniającej z oknem o rozmiarze 3, 5, 9, 15 i 35. \n",
    "Wykorzystaj polecenie `plt.subplot`. \n",
    "Przeanalizuj wpływ rozmiaru maski na wynik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmf-hkCruTVo"
   },
   "outputs": [],
   "source": [
    "def plot_convolutions_ex1(image):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "    kernel_sizes = -1, 3, 5, 9, 15, 35\n",
    "    for ax, size in zip(axes.flatten(), kernel_sizes):\n",
    "        if size == -1:\n",
    "            ax.imshow(image, cmap=\"gray\")\n",
    "            ax.set_title(\"Original\")\n",
    "        else:\n",
    "            ax.imshow(cv2.filter2D(src=image, ddepth=-1, kernel=np.ones((size, size)) / size ** 2),\n",
    "                     cmap=\"gray\")\n",
    "            ax.set_title(f\"{size}x{size} convolution\")\n",
    "        ax.axis('off')\n",
    "\n",
    "plot_convolutions_ex1(plansza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHlUB4tZuTVo"
   },
   "source": [
    "6. Wczytaj obraz _lena.png_.\n",
    "Zaobserwuj efekty filtracji dolnoprzepustowej dla obrazu rzeczywistego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ed9hL_iWuTVp"
   },
   "outputs": [],
   "source": [
    "lena = cv2.imread(\"lena.png\", cv2.IMREAD_GRAYSCALE)\n",
    "plot_convolutions_ex1(lena)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-2FnMuvuTVp"
   },
   "source": [
    "7. Niekorzystny efekt towarzyszący wykonanym filtracjom dolnoprzepustowym to utrata ostrości. \n",
    "Częściowo można go zniwelować poprzez odpowiedni dobór maski. \n",
    "Wykorzystaj maskę:  `M = np.array([1 2 1; 2 4 2; 1 2 1])`. \n",
    "Przed obliczeniami należy jeszcze wykonać normalizację - podzielić każdy element maski przez sumę wszystkich elementów: `M = M/sum(sum(M));`.\n",
    "Tak przygotowaną maskę wykorzystaj w konwolucji - wyświetl wyniki tak jak wcześniej.\n",
    "Możliwe jest też wykorzystywanie innych masek - współczynniki można dopasowywać do konkretnego problemu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-wJsEWcuTVp"
   },
   "outputs": [],
   "source": [
    "M = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "\n",
    "def plot_image(image, title=\"\", **kwargs):\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "plot_image(cv2.filter2D(src=plansza, ddepth=-1, kernel=M/np.sum(M)), \"[1 2 1; 2 4 2; 1 2 1] mask\", cmap=\"gray\")\n",
    "plot_image(cv2.filter2D(src=plansza, ddepth=-1, kernel=kernel), \"Normal 3x3 mask\", cmap=\"gray\")\n",
    "\n",
    "plot_image(cv2.filter2D(src=lena, ddepth=-1, kernel=M/np.sum(M)), \"[1 2 1; 2 4 2; 1 2 1] mask\", cmap=\"gray\")\n",
    "plot_image(cv2.filter2D(src=lena, ddepth=-1, kernel=kernel), \"Normal 3x3 mask\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybfc6TZCuTVq"
   },
   "source": [
    "8. Skuteczną i często wykorzystywaną maską jest tzw. maska Gasussa.\n",
    "Jest to zbiór liczb, które aproksymują dwuwymiarowy rozkład Gaussa. \n",
    "Parametrem jest odchylenie standardowe i rozmiar maski.\n",
    "\n",
    "9. Wykorzystując przygotowaną funkcję `fgaussian` stwórz maskę o rozmiarze $5 \\times 5$ i odchyleniu standardowym 0.5.\n",
    "  Wykorzystując funkcję `mesh` zwizualizuj filtr.\n",
    "  Sprawdź jak parametr ``odchylenie standardowe'' wpływa na ``kształt'' filtru.\n",
    "\n",
    "  Uwaga. W OpenCV dostępna jest *dedykowana* funkcja do filtracji Gaussa - `GaussianBlur`.\n",
    "  Proszę na jednym przykładzie porównać jej działanie z użytym wyżej rozwiązaniem.\n",
    "\n",
    "10. Wykonaj filtrację dla wybranych (2--3) wartości odchylenia standardowego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUTDX8IluTVq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fgaussian(size, sigma):\n",
    "     m = n = size\n",
    "     h, k = m//2, n//2\n",
    "     x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "     g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "     return g /g.sum() \n",
    "    \n",
    "    \n",
    "def mesh(fun, size, ax):    \n",
    "    X = np.arange(-size//2, size//2, 1)\n",
    "    Y = np.arange(-size//2, size//2, 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = fun\n",
    "    \n",
    "    ax.plot_surface(X, Y, Z)\n",
    "        \n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(20, 20), subplot_kw={'projection': '3d'})\n",
    "std_devs = np.linspace(0.1, 4, axes.size)\n",
    "for ax, dev in zip(axes.flatten(), std_devs):\n",
    "    mesh(fgaussian(5, dev), 5, ax)\n",
    "    ax.set_title(f\"std dev = {dev:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_functions(left_img, mid_img, **kwargs):\n",
    "    left_img = left_img.astype(np.int16)\n",
    "    mid_img = mid_img.astype(np.int16)\n",
    "    fig, (left, mid, right) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    left.imshow(left_img, cmap=\"gray\")\n",
    "    left.set_title(kwargs.get(\"left_title\", \"Original\"))\n",
    "    mid.imshow(mid_img, cmap=\"gray\")\n",
    "    mid.set_title(kwargs.get(\"mid_title\", \"\"))\n",
    "\n",
    "    right.imshow(np.abs(kwargs.get(\"operation\", np.ndarray.__sub__)(left_img, mid_img)), cmap=\"gray\")\n",
    "    right.set_title(kwargs.get(\"right_title\", \"Abs difference\"))\n",
    "    for ax in [left, mid, right]:\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def compare_gaussian_blurs(image, kernel_size, std):\n",
    "    compare_functions(\n",
    "        cv2.filter2D(src=image, ddepth=-1, kernel=fgaussian(kernel_size, std)),\n",
    "        cv2.GaussianBlur(image, (kernel_size, kernel_size), std),\n",
    "        left_title=f\"My Gaussian {kernel_size}x{kernel_size}, std: {std}\",\n",
    "        mid_title=f\"Opencv Gaussian {kernel_size}x{kernel_size}, std: {std}\"\n",
    "    )\n",
    "\n",
    "compare_gaussian_blurs(lena, 5, 0.5)\n",
    "compare_gaussian_blurs(lena, 5, 1.5)\n",
    "compare_gaussian_blurs(lena, 5, 2.5)\n",
    "compare_gaussian_blurs(lena, 5, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkN2AOHruTVr"
   },
   "source": [
    "### Filtry nieliniowe -- mediana\n",
    "\n",
    "Filtry rozmywające redukują szum, ale niekorzystnie wpływają na ostrość obrazu.\n",
    "Dlatego często wykorzystuje się filtry nieliniowe - np. filtr medianowy (dla przypomnienia: mediana - środkowa wartość w posortowanym ciągu liczb).\n",
    "\n",
    "Podstawowa różnica pomiędzy filtrami liniowymi, a nieliniowymi polega na tym, że przy filtracji liniowej na nową wartość piksela ma wpływ wartość wszystkich pikseli z otoczenia (np. uśrednianie, czasem ważone), natomiast w przypadku filtracji nieliniowej jako nowy piksel wybierana jest któraś z wartości otoczenia - według jakiegoś wskaźnika (wartość największa, najmniejsza czy właśnie mediana).\n",
    "\n",
    "\n",
    "1. Wczytaj obraz _lenaSzum.png_ (losowe 10% pikseli białych lub czarnych - tzw. zakłócenia impulsowe). Przeprowadź filtrację uśredniającą z rozmiarem maski 3x3. Wyświetl, podobnie jak wcześniej, oryginał, wynik filtracji i moduł z różnicy. Wykorzystując funkcję ``cv2.medianBlur` wykonaj filtrację medianową _lenaSzum.png_ (z rozmiarem maski $3 \\times 3$). Wyświetl, podobnie jak wcześniej, oryginał, wynik filtracji i moduł z różnicy. Która filtracja lepiej radzi sobie z tego typu szumem?\n",
    "\n",
    "  Uwaga. Taki sam efekt da również użycie funkcji `signal.medfilt2d`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ICkvyp3uTVr"
   },
   "outputs": [],
   "source": [
    "lena_szum = cv2.imread(\"lenaSzum.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def compare_median_blurs(image, kernel_size):\n",
    "    compare_functions(\n",
    "        image,\n",
    "        cv2.medianBlur(image, kernel_size),\n",
    "        mid_title=f\"Median blur with {kernel_size} kernel\"\n",
    "    )\n",
    "\n",
    "compare_median_blurs(lena_szum, 3)\n",
    "compare_median_blurs(lena_szum, 5)\n",
    "compare_median_blurs(lena_szum, 7)\n",
    "compare_median_blurs(lena_szum, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSdorMgxuTVr"
   },
   "source": [
    "2. Przeprowadź filtrację uśredniającą, a następnie medianową obrazu _lena.png_.\n",
    "   Wyniki porównaj - dla obu wyświetl: oryginał, wynik filtracji i moduł z różnicy.\n",
    "   Szczególną uwagę zwróć na ostrość i krawędzie.\n",
    "   W której filtracji krawędzie zostają lepiej zachowane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g2nnTPruTVs"
   },
   "outputs": [],
   "source": [
    "def avg_filter(size):\n",
    "    return np.ones((size, size)) / (size * size)\n",
    "\n",
    "def compare_median_and_avg(image, kernel_size):\n",
    "    compare_functions(\n",
    "        cv2.filter2D(src=image, ddepth=-1, kernel=avg_filter(kernel_size)),\n",
    "        cv2.medianBlur(image, kernel_size),\n",
    "        left_title=f\"Average blur {kernel_size} size\",\n",
    "        mid_title=f\"Median blur {kernel_size} size\"\n",
    "    )\n",
    "\n",
    "compare_median_and_avg(lena_szum, 3)\n",
    "compare_median_and_avg(lena_szum, 5)\n",
    "compare_median_and_avg(lena_szum, 7)\n",
    "compare_median_and_avg(lena_szum, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOMWoBCJuTVs"
   },
   "source": [
    "3. Ciekawy efekt można uzyskać wykonując filtrację medianową wielokrotnie. Określa się go mianem  posteryzacji.  W wyniku przetwarzania z obrazka usunięte zostają detale, a duże obszary uzyskują tą samą wartość jasności.  Wykonaj operację mediany $5 \\times 5$ na obrazie _lena.png_ 10-krotnie. (wykorzystaj np. pętlę `for`).\n",
    "\n",
    "\n",
    "Inne filtry nieliniowe:\n",
    "- filtr modowy - moda (dominanta) zamiast mediany,\n",
    "- filtr olimpijski - średnia z podzbioru otoczenia (bez wartości ekstremalnych),\n",
    "- hybrydowy filtr medianowy - mediana obliczana osobno w różnych podzbiorach otoczenia (np. kształt ``x'',``+''), a jako wynik brana jest mediana ze zbioru wartość elementu centralnego, mediana z ``x'' i mediana z ``+'',\n",
    "- filtr minimalny i maksymalny (będą omówione przy okazji operacji morfologicznych w dalszej części kursu).\n",
    "\n",
    "\n",
    "Warto zdawać sobie sprawę, z szerokich możliwości dopasowywania rodzaju filtracji do konkretnego rozważanego problemu i rodzaju zaszumienia występującego na obrazie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSFMyFBluTVt"
   },
   "outputs": [],
   "source": [
    "def compare_multimedian(image, kernel_size, num_iter):\n",
    "    for _ in range(num_iter):\n",
    "        locals()[\"result\"] = cv2.medianBlur(locals().get(\"result\", image), kernel_size)\n",
    "    compare_functions(\n",
    "        image,\n",
    "        locals()[\"result\"],\n",
    "        left_title=\"Original\",\n",
    "        mid_title=f\"Multimedian with {kernel_size}x{kernel_size} kernel, {num_iter} iterations\"\n",
    "    )\n",
    "\n",
    "compare_multimedian(lena_szum, 5, 5)\n",
    "compare_multimedian(lena_szum, 5, 10)\n",
    "compare_multimedian(lena_szum, 5, 20)\n",
    "compare_multimedian(lena_szum, 5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPKUMojBuTVt"
   },
   "source": [
    "## Filtry liniowe górnoprzepustowe (wyostrzające, wykrywające krawędzie)\n",
    "\n",
    "Zadaniem filtrów górnoprzepustowych jest wydobywanie z obrazu składników odpowiedzialnych za szybkie zmiany jasności - konturów, krawędzi, drobnych elementów tekstury.\n",
    "\n",
    "### Laplasjan (wykorzystanie drugiej pochodnej obrazu)\n",
    "\n",
    "1. Wczytaj obraz _moon.png_.\n",
    "\n",
    "2. Wprowadź podstawową maskę laplasjanu:\n",
    "\\begin{equation}\n",
    "M = \n",
    "\\begin{bmatrix}\n",
    "0 & 1& 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "3. Przed rozpoczęciem obliczeń należy dokonać normalizacji maski - dla rozmiaru $3 \\times 3$ podzielić każdy element przez 9.\n",
    "   Proszę zwrócić uwagę, że nie można tu zastosować takiej samej normalizacji, jak dla filtrów dolnoprzepustowanych, gdyż skutkowałby to dzieleniem przez 0.\n",
    "\n",
    "4. Wykonaj konwolucję obrazu z maską (`c2.filter2D`). Przed wyświetleniem, wynikowy obraz należy poddać normalizacji (występują ujemne wartości). Najczęściej wykonuje się jedną z dwóch operacji:\n",
    "- skalowanie (np. poprzez dodatnie 128 do każdego z pikseli),\n",
    "- moduł (wartość bezwzględna).\n",
    "\n",
    "Wykonaj obie normalizacje. \n",
    "Na wspólnym wykresie wyświetl obraz oryginalny oraz przefiltrowany po obu normalizacjach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDE-NzUzuTVt"
   },
   "outputs": [],
   "source": [
    "moon = cv2.imread(\"moon.png\", cv2.IMREAD_GRAYSCALE)\n",
    "laplace_mask = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]) / 9\n",
    "\n",
    "laplace_moon = moon.copy()\n",
    "\n",
    "def subplot_image(ax, image, title=\"\", **kwargs):\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(image, cmap=kwargs.get(\"cmap\", \"gray\"), **kwargs)\n",
    "\n",
    "def laplace_transform(image, norm_func, norm_name):\n",
    "    _, (org, laplace) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    cv2.filter2D(src=image, ddepth=-1, kernel=laplace_mask, dst=laplace_moon)\n",
    "    subplot_image(org, image, \"Original\")\n",
    "    subplot_image(\n",
    "        laplace, \n",
    "        norm_func(laplace_moon),\n",
    "        f\"Laplace transform with {norm_name} normalization\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "laplace_transform(moon, lambda img: img + 128, '\"add 128\" scaling')\n",
    "laplace_transform(moon, np.abs, \"abs value\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNAsSrd-uTVu"
   },
   "source": [
    "7. Efekt wyostrzenia uzyskuje się po odjęciu/dodaniu (zależy do maski) rezultatu filtracji laplasjanowej i oryginalnego obrazu. Wyświetl na jednym wykresie: obraz oryginalny, sumę oryginału i wyniku filtracji oraz różnicę (bezwzględną) oryginału i wyniku filtracji.\n",
    " Uwaga. Aby uniknąć artefaktów, należy obraz wejściowy przekonwertować do formatu ze znakiem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2-IHdLjuTVu"
   },
   "outputs": [],
   "source": [
    "compare_functions(\n",
    "    moon,\n",
    "    laplace_moon,\n",
    "    operation=np.ndarray.__add__,\n",
    "    mid_title=\"Laplaced\",\n",
    "    right_title=\"Original + Laplace\"\n",
    ")\n",
    "\n",
    "compare_functions(\n",
    "    moon.astype(np.int16),\n",
    "    laplace_moon,\n",
    "    mid_title=\"Laplaced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7UEkpUFuTVu"
   },
   "source": [
    "### Gradienty (wykorzystanie pierwszej pochodnej obrazu)\n",
    "\n",
    "1. Wczytaj obraz _kw.png_. Stwórz odpowiednie maski opisane w kolejnych punktach i dokonaj filtracji.\n",
    "2. Wykorzystując gradient Robertsa przeprowadź detekcję krawędzi - poprzez wykonanie konwolucji obrazu z daną maską:\n",
    "\\begin{equation}\n",
    "R1 = \\begin{bmatrix} 0 & 0 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}   \n",
    "R2 = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & -1 \\\\ 0 & 1 & 0 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Wykorzystaj stworzony wcześniej kod (przy laplasjanie) - dwie metody normalizacji oraz sposób wyświetlania.\n",
    "\n",
    "3. Analogicznie przeprowadź detekcję krawędzi za pomocą gradientu Prewitta (pionowy i poziomy)\n",
    "\\begin{equation}\n",
    "P1 = \\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1 \\end{bmatrix}   \n",
    "P2 = \\begin{bmatrix} -1 & -1 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "4. Podobnie skonstruowany jest gradient Sobela (występuje osiem masek, zaprezentowane są dwie ``prostopadłe''):\n",
    "\\begin{equation}\n",
    "S1 = \\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}   \n",
    "S2 = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Przeprowadź detekcję krawędzi za pomocą gradientu Sobela. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhwEYhsZuTVv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kw = cv2.imread(\"kw.png\", cv2.IMREAD_GRAYSCALE)\n",
    "R1 = np.array([[0, 0, 0], [-1, 0, 0], [0, 1, 0]])\n",
    "R2 = np.fliplr(R1)\n",
    "P1 = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "P2 = P1.T\n",
    "S1 = P1; S1[1] *= 2\n",
    "S2 = S1.T\n",
    "\n",
    "def apply_convolution(image, kernel_globals_key):\n",
    "    kernel = globals()[kernel_globals_key]\n",
    "    _, (org, cv) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    subplot_image(\n",
    "        org, \n",
    "        image, \n",
    "        title=\"Original\"\n",
    "    )\n",
    "    subplot_image(\n",
    "        cv, \n",
    "        cv2.filter2D(src=image, ddepth=-1, kernel=kernel), \n",
    "        title=f\"{kernel_globals_key} convolution\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "for conv in [\"R1\", \"R2\", \"P1\", \"P2\", \"S1\", \"S2\"]:\n",
    "    apply_convolution(kw, conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56RoscNzuTVv"
   },
   "source": [
    "5. Na podstawie dwóch ortogonalnych masek np. Sobela można stworzyć tzw. filtr kombinowany - pierwiastek kwadratowy z sumy kwadratów gradientów:\n",
    "\\begin{equation}\n",
    "OW = \\sqrt{(O * S1)^2 + (O * S2)^2}\n",
    "\\end{equation}\n",
    "gdzie:  $OW$ - obraz wyjściowy, $O$ - obraz oryginalny (wejściowy), $S1,S2$ - maski Sobela, $*$ - operacja konwolucji.\n",
    "\n",
    "Zaimplementuj filtr kombinowany.\n",
    "\n",
    "Uwaga. Proszę zwrócić uwagę na konieczność zmiany formatu danych obrazu wejściowego - na typ znakiem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pobro8ZkuTVv"
   },
   "outputs": [],
   "source": [
    "def conv(image, kernel, dtype=np.uint8):\n",
    "    return cv2.filter2D(src=image.astype(dtype), ddepth=-1, kernel=kernel)\n",
    "\n",
    "def norm_combined_conv(image):\n",
    "    return np.sqrt(np.square(conv(image, S1, np.uint16)) + np.square(conv(image, S2, np.uint16)))\n",
    "\n",
    "def abs_combined_conv(image):\n",
    "    return np.abs(conv(image, S1) + conv(image, S2))\n",
    "\n",
    "def display_conv(image, method):\n",
    "    _, (org, cv) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    subplot_image(org, image, \"Original\")\n",
    "    subplot_image(cv, method(image), method.__name__)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_conv(kw, norm_combined_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dsJBZyluTVw"
   },
   "source": [
    "6. Istnieje alternatywna wersja filtra kombinowanego, która zamiast pierwiastka z sumy kwadratów wykorzystuje sumę modułów (prostsze obliczenia). \n",
    "Zaimplementuj tę wersję. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJMIOBGnuTVw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_conv(kw, abs_combined_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-3dRwiiuTVw"
   },
   "source": [
    "7. Wczytaj plik _jet.png_ (zamiast _kw.png_).\n",
    "Sprawdź działanie obu wariantów filtracji kombinowanej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAm2toQRuTVw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jet = cv2.imread(\"jet.png\", cv2.IMREAD_GRAYSCALE)\n",
    "display_conv(jet, norm_combined_conv)\n",
    "display_conv(jet, abs_combined_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
